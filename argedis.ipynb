{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/nbuser/anaconda3_420/lib/python3.5/site-packages\n",
      "Requirement already satisfied: scipy in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from lightgbm)\n",
      "Requirement already satisfied: numpy in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from lightgbm)\n",
      "Requirement already satisfied: scikit-learn in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from lightgbm)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-0.7.post3.tar.gz (450kB)\n",
      "\u001b[K    100% |################################| 460kB 1.9MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from xgboost)\n",
      "Requirement already satisfied: scipy in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from xgboost)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Running setup.py bdist_wheel for xgboost ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/ca/b3/02/d44d5e12c5c1eecff4a822555bac96b182551cd5e13c4795f6\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.7.post3\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "archive = zipfile.ZipFile('test.csv.zip', 'r')\n",
    "test = pd.read_csv(archive.open('test.csv'), sep=\";\", decimal=\",\",parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile('train.csv.zip', 'r')\n",
    "train = pd.read_csv(archive.open('train.csv'), sep=\";\", decimal=\",\",parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "test.date = test.date.str.split('-').apply(lambda x: datetime.datetime(int(x[0]),int(x[1]),int(x[2])))\n",
    "train.date = train.date.str.split('-').apply(lambda x: datetime.datetime(int(x[0]),int(x[1]),int(x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dayofweek'] = train.date.dt.dayofweek\n",
    "test['dayofweek'] = test.date.dt.dayofweek\n",
    "train['quarter'] = train.date.dt.quarter\n",
    "test['quarter'] = test.date.dt.quarter\n",
    "train['week'] = train.date.dt.week\n",
    "test['week'] = test.date.dt.week\n",
    "train['month'] = train.date.dt.month\n",
    "test['month'] = test.date.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some more feature engineering\n",
    "train[\"qteG\"] = train.article_nom.str.extract('(\\d+)G',expand=True).fillna(0).astype(int)\n",
    "test[\"qteG\"] = test.article_nom.str.extract('(\\d+)G',expand=True).fillna(0).astype(int)\n",
    "train['qteX'] = train.article_nom.str.extract('X ?(\\d)',expand=True).fillna(0).astype(int)\n",
    "test['qteX'] = test.article_nom.str.extract('X ?(\\d)',expand=True).fillna(0).astype(int)\n",
    "train['qteMl'] = train.article_nom.str.extract('(\\d+) ?Ml',expand=True).fillna(0).astype(int)\n",
    "test['qteMl'] = test.article_nom.str.extract('(\\d+) ?Ml',expand=True).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = train.set_index('id').qte_article_vendue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['implant', 'article_nom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoders = {}\n",
    "for cat in cat_features:\n",
    "     label_encoders.update({cat:preprocessing.LabelEncoder()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat, le in label_encoders.items():\n",
    "    cat_str = cat+'_label'\n",
    "    train[cat_str] = le.fit_transform(train[cat])\n",
    "    test[cat_str] = le.transform(test[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##aggregates\n",
    "#data = pd.concat([train.set_index('id'),test.set_index('id')],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.groupby(['article_nom','date','implant']).qte_article_vendue.rolling(2).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = train.set_index('id').select_dtypes(include=['float64','int64']).drop('qte_article_vendue', axis=1)\n",
    "testset = test.set_index('id').select_dtypes(include=['float64','int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "regressor = ExtraTreesRegressor().fit(trainingset, ytrain)\n",
    "#lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(trainingset, ytrain)\n",
    "model = SelectFromModel(regressor, prefit=True)\n",
    "X = model.transform(trainingset)\n",
    "Xpredict = model.transform(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vente_j_7', 'vente_j_8_14', 'vente_cat5_j_7', 'vente_cat5_j_8_14',\n",
       "       'vente_cat4_j_7', 'vente_cat4_j_8_14', 'dayofweek', 'qteG',\n",
       "       'implant_label', 'article_nom_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingset.columns[model.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainingset, ytrain, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\tvalid_0's rmse: 0.824954\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's rmse: 0.794949\n",
      "[3]\tvalid_0's rmse: 0.769341\n",
      "[4]\tvalid_0's rmse: 0.748389\n",
      "[5]\tvalid_0's rmse: 0.729549\n",
      "[6]\tvalid_0's rmse: 0.714751\n",
      "[7]\tvalid_0's rmse: 0.701308\n",
      "[8]\tvalid_0's rmse: 0.690887\n",
      "[9]\tvalid_0's rmse: 0.681769\n",
      "[10]\tvalid_0's rmse: 0.67352\n",
      "[11]\tvalid_0's rmse: 0.666433\n",
      "[12]\tvalid_0's rmse: 0.660194\n",
      "[13]\tvalid_0's rmse: 0.654688\n",
      "[14]\tvalid_0's rmse: 0.65034\n",
      "[15]\tvalid_0's rmse: 0.646665\n",
      "[16]\tvalid_0's rmse: 0.64352\n",
      "[17]\tvalid_0's rmse: 0.640808\n",
      "[18]\tvalid_0's rmse: 0.638041\n",
      "[19]\tvalid_0's rmse: 0.635866\n",
      "[20]\tvalid_0's rmse: 0.634015\n",
      "[21]\tvalid_0's rmse: 0.632183\n",
      "[22]\tvalid_0's rmse: 0.630454\n",
      "[23]\tvalid_0's rmse: 0.629355\n",
      "[24]\tvalid_0's rmse: 0.627942\n",
      "[25]\tvalid_0's rmse: 0.626457\n",
      "[26]\tvalid_0's rmse: 0.625055\n",
      "[27]\tvalid_0's rmse: 0.624297\n",
      "[28]\tvalid_0's rmse: 0.623282\n",
      "[29]\tvalid_0's rmse: 0.622281\n",
      "[30]\tvalid_0's rmse: 0.621367\n",
      "[31]\tvalid_0's rmse: 0.620757\n",
      "[32]\tvalid_0's rmse: 0.620001\n",
      "[33]\tvalid_0's rmse: 0.619423\n",
      "[34]\tvalid_0's rmse: 0.618684\n",
      "[35]\tvalid_0's rmse: 0.617698\n",
      "[36]\tvalid_0's rmse: 0.6168\n",
      "[37]\tvalid_0's rmse: 0.616534\n",
      "[38]\tvalid_0's rmse: 0.615811\n",
      "[39]\tvalid_0's rmse: 0.615377\n",
      "[40]\tvalid_0's rmse: 0.614908\n",
      "[41]\tvalid_0's rmse: 0.614696\n",
      "[42]\tvalid_0's rmse: 0.61408\n",
      "[43]\tvalid_0's rmse: 0.613596\n",
      "[44]\tvalid_0's rmse: 0.612832\n",
      "[45]\tvalid_0's rmse: 0.612368\n",
      "[46]\tvalid_0's rmse: 0.611901\n",
      "[47]\tvalid_0's rmse: 0.611447\n",
      "[48]\tvalid_0's rmse: 0.610893\n",
      "[49]\tvalid_0's rmse: 0.610597\n",
      "[50]\tvalid_0's rmse: 0.61004\n",
      "[51]\tvalid_0's rmse: 0.609743\n",
      "[52]\tvalid_0's rmse: 0.609457\n",
      "[53]\tvalid_0's rmse: 0.609121\n",
      "[54]\tvalid_0's rmse: 0.608916\n",
      "[55]\tvalid_0's rmse: 0.608737\n",
      "[56]\tvalid_0's rmse: 0.608501\n",
      "[57]\tvalid_0's rmse: 0.608146\n",
      "[58]\tvalid_0's rmse: 0.607998\n",
      "[59]\tvalid_0's rmse: 0.607859\n",
      "[60]\tvalid_0's rmse: 0.607631\n",
      "[61]\tvalid_0's rmse: 0.607442\n",
      "[62]\tvalid_0's rmse: 0.607241\n",
      "[63]\tvalid_0's rmse: 0.606984\n",
      "[64]\tvalid_0's rmse: 0.606862\n",
      "[65]\tvalid_0's rmse: 0.606788\n",
      "[66]\tvalid_0's rmse: 0.606796\n",
      "[67]\tvalid_0's rmse: 0.606517\n",
      "[68]\tvalid_0's rmse: 0.606409\n",
      "[69]\tvalid_0's rmse: 0.606345\n",
      "[70]\tvalid_0's rmse: 0.605998\n",
      "[71]\tvalid_0's rmse: 0.605796\n",
      "[72]\tvalid_0's rmse: 0.605436\n",
      "[73]\tvalid_0's rmse: 0.605242\n",
      "[74]\tvalid_0's rmse: 0.605226\n",
      "[75]\tvalid_0's rmse: 0.605071\n",
      "[76]\tvalid_0's rmse: 0.604913\n",
      "[77]\tvalid_0's rmse: 0.604748\n",
      "[78]\tvalid_0's rmse: 0.604586\n",
      "[79]\tvalid_0's rmse: 0.60469\n",
      "[80]\tvalid_0's rmse: 0.604479\n",
      "[81]\tvalid_0's rmse: 0.60429\n",
      "[82]\tvalid_0's rmse: 0.603949\n",
      "[83]\tvalid_0's rmse: 0.603777\n",
      "[84]\tvalid_0's rmse: 0.603497\n",
      "[85]\tvalid_0's rmse: 0.603526\n",
      "[86]\tvalid_0's rmse: 0.603344\n",
      "[87]\tvalid_0's rmse: 0.60326\n",
      "[88]\tvalid_0's rmse: 0.603202\n",
      "[89]\tvalid_0's rmse: 0.603011\n",
      "[90]\tvalid_0's rmse: 0.602634\n",
      "[91]\tvalid_0's rmse: 0.602547\n",
      "[92]\tvalid_0's rmse: 0.602456\n",
      "[93]\tvalid_0's rmse: 0.60251\n",
      "[94]\tvalid_0's rmse: 0.602468\n",
      "[95]\tvalid_0's rmse: 0.602376\n",
      "[96]\tvalid_0's rmse: 0.60223\n",
      "[97]\tvalid_0's rmse: 0.602163\n",
      "[98]\tvalid_0's rmse: 0.602211\n",
      "[99]\tvalid_0's rmse: 0.602072\n",
      "[100]\tvalid_0's rmse: 0.602145\n",
      "[101]\tvalid_0's rmse: 0.602033\n",
      "[102]\tvalid_0's rmse: 0.601907\n",
      "[103]\tvalid_0's rmse: 0.601749\n",
      "[104]\tvalid_0's rmse: 0.601565\n",
      "[105]\tvalid_0's rmse: 0.601525\n",
      "[106]\tvalid_0's rmse: 0.601463\n",
      "[107]\tvalid_0's rmse: 0.601464\n",
      "[108]\tvalid_0's rmse: 0.601419\n",
      "[109]\tvalid_0's rmse: 0.601331\n",
      "[110]\tvalid_0's rmse: 0.601322\n",
      "[111]\tvalid_0's rmse: 0.60113\n",
      "[112]\tvalid_0's rmse: 0.601027\n",
      "[113]\tvalid_0's rmse: 0.600924\n",
      "[114]\tvalid_0's rmse: 0.600925\n",
      "[115]\tvalid_0's rmse: 0.600872\n",
      "[116]\tvalid_0's rmse: 0.601014\n",
      "[117]\tvalid_0's rmse: 0.601064\n",
      "[118]\tvalid_0's rmse: 0.60098\n",
      "[119]\tvalid_0's rmse: 0.601012\n",
      "[120]\tvalid_0's rmse: 0.600805\n",
      "[121]\tvalid_0's rmse: 0.600885\n",
      "[122]\tvalid_0's rmse: 0.600686\n",
      "[123]\tvalid_0's rmse: 0.600611\n",
      "[124]\tvalid_0's rmse: 0.600603\n",
      "[125]\tvalid_0's rmse: 0.600572\n",
      "[126]\tvalid_0's rmse: 0.600507\n",
      "[127]\tvalid_0's rmse: 0.600321\n",
      "[128]\tvalid_0's rmse: 0.600163\n",
      "[129]\tvalid_0's rmse: 0.600242\n",
      "[130]\tvalid_0's rmse: 0.600336\n",
      "[131]\tvalid_0's rmse: 0.600287\n",
      "[132]\tvalid_0's rmse: 0.600224\n",
      "[133]\tvalid_0's rmse: 0.600217\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's rmse: 0.600163\n",
      "Start predicting...\n",
      "The rmse of prediction is: 0.600163386271\n",
      "Feature importances: [207, 186, 89, 250, 116, 67, 186, 226, 127, 34, 178, 160, 91, 60, 144, 172, 75, 48, 193, 62, 19, 2, 25, 1, 29, 102, 26, 5, 13, 13, 19, 679, 1032, 364, 264, 266, 373, 299, 13, 451, 43, 304, 14, 65, 167, 293]\n"
     ]
    }
   ],
   "source": [
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.LGBMRegressor(objective='regression',\n",
    "                        num_leaves=60,\n",
    "                        learning_rate=0.1,\n",
    "                        n_estimators=150, random_state=42)\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric='rmse',\n",
    "        early_stopping_rounds=5)\n",
    "\n",
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration_)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "\n",
    "# feature importances\n",
    "print('Feature importances:', list(gbm.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vente_j_8_14\n",
      "vente_j_7\n",
      "week\n",
      "vente_cat4_j_8_14\n",
      "vente_cat5_j_7\n",
      "qteG\n",
      "dayofweek\n",
      "article_nom_label\n",
      "vente_cat4_j_7\n",
      "vente_cat5_j_8_14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in np.argsort(gbm.feature_importances_)[::-1][:10]:\n",
    "    print(trainingset.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module xgboost.sklearn:\n",
      "\n",
      "fit(X, y, sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None) method of xgboost.sklearn.XGBRegressor instance\n",
      "    Fit the gradient boosting model\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array_like\n",
      "        Feature matrix\n",
      "    y : array_like\n",
      "        Labels\n",
      "    sample_weight : array_like\n",
      "        instance weights\n",
      "    eval_set : list, optional\n",
      "        A list of (X, y) tuple pairs to use as a validation set for\n",
      "        early-stopping\n",
      "    eval_metric : str, callable, optional\n",
      "        If a str, should be a built-in evaluation metric to use. See\n",
      "        doc/parameter.md. If callable, a custom evaluation metric. The call\n",
      "        signature is func(y_predicted, y_true) where y_true will be a\n",
      "        DMatrix object such that you may need to call the get_label\n",
      "        method. It must return a str, value pair where the str is a name\n",
      "        for the evaluation and value is the value of the evaluation\n",
      "        function. This objective is always minimized.\n",
      "    early_stopping_rounds : int\n",
      "        Activates early stopping. Validation error needs to decrease at\n",
      "        least every <early_stopping_rounds> round(s) to continue training.\n",
      "        Requires at least one item in evals.  If there's more than one,\n",
      "        will use the last. Returns the model from the last iteration\n",
      "        (not the best one). If early stopping occurs, the model will\n",
      "        have three additional fields: bst.best_score, bst.best_iteration\n",
      "        and bst.best_ntree_limit.\n",
      "        (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n",
      "        and/or num_class appears in the parameters)\n",
      "    verbose : bool\n",
      "        If `verbose` and an evaluation set is used, writes the evaluation\n",
      "        metric measured on the validation set to stderr.\n",
      "    xgb_model : str\n",
      "        file name of stored xgb model or 'Booster' instance Xgb model to be\n",
      "        loaded before training (allows training continuation).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xgbReg.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:0.826859\n",
      "Will train until validation_0-rmse hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-rmse:0.798098\n",
      "[2]\tvalidation_0-rmse:0.772668\n",
      "[3]\tvalidation_0-rmse:0.751844\n",
      "[4]\tvalidation_0-rmse:0.734243\n",
      "[5]\tvalidation_0-rmse:0.719077\n",
      "[6]\tvalidation_0-rmse:0.706491\n",
      "[7]\tvalidation_0-rmse:0.696243\n",
      "[8]\tvalidation_0-rmse:0.68749\n",
      "[9]\tvalidation_0-rmse:0.679917\n",
      "[10]\tvalidation_0-rmse:0.673718\n",
      "[11]\tvalidation_0-rmse:0.66858\n",
      "[12]\tvalidation_0-rmse:0.663864\n",
      "[13]\tvalidation_0-rmse:0.660004\n",
      "[14]\tvalidation_0-rmse:0.656571\n",
      "[15]\tvalidation_0-rmse:0.653245\n",
      "[16]\tvalidation_0-rmse:0.65026\n",
      "[17]\tvalidation_0-rmse:0.647687\n",
      "[18]\tvalidation_0-rmse:0.645823\n",
      "[19]\tvalidation_0-rmse:0.644358\n",
      "[20]\tvalidation_0-rmse:0.642686\n",
      "[21]\tvalidation_0-rmse:0.641419\n",
      "[22]\tvalidation_0-rmse:0.63989\n",
      "[23]\tvalidation_0-rmse:0.638882\n",
      "[24]\tvalidation_0-rmse:0.6377\n",
      "[25]\tvalidation_0-rmse:0.6365\n",
      "[26]\tvalidation_0-rmse:0.635653\n",
      "[27]\tvalidation_0-rmse:0.634763\n",
      "[28]\tvalidation_0-rmse:0.634005\n",
      "[29]\tvalidation_0-rmse:0.632881\n",
      "[30]\tvalidation_0-rmse:0.632189\n",
      "[31]\tvalidation_0-rmse:0.631473\n",
      "[32]\tvalidation_0-rmse:0.630768\n",
      "[33]\tvalidation_0-rmse:0.630484\n",
      "[34]\tvalidation_0-rmse:0.630282\n",
      "[35]\tvalidation_0-rmse:0.629654\n",
      "[36]\tvalidation_0-rmse:0.629012\n",
      "[37]\tvalidation_0-rmse:0.628461\n",
      "[38]\tvalidation_0-rmse:0.627771\n",
      "[39]\tvalidation_0-rmse:0.627302\n",
      "[40]\tvalidation_0-rmse:0.626285\n",
      "[41]\tvalidation_0-rmse:0.626089\n",
      "[42]\tvalidation_0-rmse:0.625384\n",
      "[43]\tvalidation_0-rmse:0.624773\n",
      "[44]\tvalidation_0-rmse:0.624378\n",
      "[45]\tvalidation_0-rmse:0.624054\n",
      "[46]\tvalidation_0-rmse:0.623799\n",
      "[47]\tvalidation_0-rmse:0.623576\n",
      "[48]\tvalidation_0-rmse:0.623227\n",
      "[49]\tvalidation_0-rmse:0.62293\n",
      "[50]\tvalidation_0-rmse:0.622721\n",
      "[51]\tvalidation_0-rmse:0.62275\n",
      "[52]\tvalidation_0-rmse:0.622563\n",
      "[53]\tvalidation_0-rmse:0.62257\n",
      "[54]\tvalidation_0-rmse:0.622452\n",
      "[55]\tvalidation_0-rmse:0.622265\n",
      "[56]\tvalidation_0-rmse:0.621668\n",
      "[57]\tvalidation_0-rmse:0.621515\n",
      "[58]\tvalidation_0-rmse:0.62147\n",
      "[59]\tvalidation_0-rmse:0.621317\n",
      "[60]\tvalidation_0-rmse:0.62119\n",
      "[61]\tvalidation_0-rmse:0.620701\n",
      "[62]\tvalidation_0-rmse:0.620731\n",
      "[63]\tvalidation_0-rmse:0.620737\n",
      "[64]\tvalidation_0-rmse:0.620449\n",
      "[65]\tvalidation_0-rmse:0.620349\n",
      "[66]\tvalidation_0-rmse:0.619975\n",
      "[67]\tvalidation_0-rmse:0.619659\n",
      "[68]\tvalidation_0-rmse:0.619545\n",
      "[69]\tvalidation_0-rmse:0.619322\n",
      "[70]\tvalidation_0-rmse:0.619293\n",
      "[71]\tvalidation_0-rmse:0.618752\n",
      "[72]\tvalidation_0-rmse:0.618843\n",
      "[73]\tvalidation_0-rmse:0.618651\n",
      "[74]\tvalidation_0-rmse:0.618492\n",
      "[75]\tvalidation_0-rmse:0.618023\n",
      "[76]\tvalidation_0-rmse:0.617687\n",
      "[77]\tvalidation_0-rmse:0.617492\n",
      "[78]\tvalidation_0-rmse:0.617392\n",
      "[79]\tvalidation_0-rmse:0.617372\n",
      "[80]\tvalidation_0-rmse:0.617398\n",
      "[81]\tvalidation_0-rmse:0.617571\n",
      "[82]\tvalidation_0-rmse:0.617296\n",
      "[83]\tvalidation_0-rmse:0.616955\n",
      "[84]\tvalidation_0-rmse:0.616561\n",
      "[85]\tvalidation_0-rmse:0.616405\n",
      "[86]\tvalidation_0-rmse:0.616325\n",
      "[87]\tvalidation_0-rmse:0.616226\n",
      "[88]\tvalidation_0-rmse:0.61602\n",
      "[89]\tvalidation_0-rmse:0.615876\n",
      "[90]\tvalidation_0-rmse:0.616279\n",
      "[91]\tvalidation_0-rmse:0.616269\n",
      "[92]\tvalidation_0-rmse:0.615728\n",
      "[93]\tvalidation_0-rmse:0.615591\n",
      "[94]\tvalidation_0-rmse:0.615444\n",
      "[95]\tvalidation_0-rmse:0.615076\n",
      "[96]\tvalidation_0-rmse:0.614916\n",
      "[97]\tvalidation_0-rmse:0.614819\n",
      "[98]\tvalidation_0-rmse:0.614784\n",
      "[99]\tvalidation_0-rmse:0.614503\n",
      "Start predicting...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() got an unexpected keyword argument 'num_iteration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cfdb83a89473>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start predicting...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgbReg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The rmse of prediction is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'num_iteration'"
     ]
    }
   ],
   "source": [
    "xgbReg = xgb.XGBRegressor(nthread=-1, min_child_weight=4, subsample=0.9, max_depth=5) \n",
    "xgbReg.fit(X_train, y_train,\n",
    "        eval_metric='rmse',\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        early_stopping_rounds=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start predicting...\n",
      "The rmse of prediction is: 0.614503423079\n",
      "Feature importances: [0.016853932, 0.015449438, 0.0066713481, 0.028441012, 0.014396068, 0.0056179776, 0.018258426, 0.024227528, 0.019662922, 0.0070224721, 0.016151685, 0.015098315, 0.0056179776, 0.0049157306, 0.013693821, 0.020365169, 0.0014044944, 0.0056179776, 0.0098314611, 0.022120787, 0.001755618, 0.0, 0.0052668541, 0.0010533708, 0.0045646066, 0.025632022, 0.0056179776, 0.0, 0.0, 0.0024578653, 0.0049157306, 0.11341292, 0.18820225, 0.04985955, 0.031601124, 0.023174157, 0.051966291, 0.047752809, 0.0038623596, 0.066011235, 0.0070224721, 0.024578651, 0.0003511236, 0.0080758426, 0.024929775, 0.036516853]\n",
      "vente_j_8_14\n",
      "vente_j_7\n",
      "week\n",
      "vente_cat4_j_8_14\n",
      "vente_cat5_j_7\n",
      "dayofweek\n",
      "article_nom_label\n",
      "vente_cat5_j_8_14\n",
      "t_9h_rouen\n",
      "retour_zone_1\n"
     ]
    }
   ],
   "source": [
    "print('Start predicting...')\n",
    "# predict\n",
    "y_pred2 = xgbReg.predict(X_test)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred2) ** 0.5)\n",
    "\n",
    "# feature importances\n",
    "print('Feature importances:', list(xgbReg.feature_importances_))\n",
    "\n",
    "import numpy as np\n",
    "for i in np.argsort(xgbReg.feature_importances_)[::-1][:10]:\n",
    "    print(trainingset.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of prediction is: 0.603037683074\n"
     ]
    }
   ],
   "source": [
    "print('The rmse of prediction is:', mean_squared_error(y_test, 0.5*(y_pred+y_pred2)) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub = gbm.predict(testset, num_iteration=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sub2 = xgbReg.predict(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(0.5*(y_sub+y_sub2),index=testset.index,columns=['quantite_vendue']).to_csv('sub.csv',sep=';',decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
